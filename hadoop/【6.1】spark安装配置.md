# Spark

> Spark是一种基于内存的快速、通用、可扩展的大数据分析计算引擎。

1. spark是基于MR的，但是优化了其中的计算过程，使用内存来代替计算过程
2. Spark基于Scala语言开发，更适合迭代计算和数据挖掘计算
3. Spark计算模型丰富，MR的计算模型两个：Mapper和Reducer，Scala计算模型：map、filter、groupBy、sortBy等

## 安装Scala 2.13.15

Scala安装步骤略

> 所有节点都需要安装 

## 下载Spark 

下载的版本是spark-3.5.4-bin-hadoop3.tgz，对应的hadoop版本是hadoop 3 以后

## 解压Spark

```shell
tar -zxvf spark-3.5.4-bin-hadoop3.tgz
```

## 配置环境变量

```shell
#编辑以下文件
vi /etc/profile

#加入以下内容
#SPARK_HOME
export SPARK_HOME=/usr/local/spark-3.5.4-bin-hadoop3
export SPARK_PYTHON_HOME=/usr/local/spark-3.5.4-bin-hadoop3/python
export PATH=$SPARK_HOME/bin:$SPARK_HOME/sbin:$SPARK_PYTHON_HOME:$PATH

#保存文件并使配置生效
source /etc/profile
```

## Local模式

### scala java启动

```shell
spark-shell
```

可以看到一下内容：

```
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
24/12/27 10:49:56 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Spark context Web UI available at http://hd.master:4040
Spark context available as 'sc' (master = local[*], app id = local-1735267797890).
Spark session available as 'spark'.
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /___/ .__/\_,_/_/ /_/\_\   version 3.5.4
      /_/

Using Scala version 2.12.18 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_211)
Type in expressions to have them evaluated.
Type :help for more information.
```

可以访问页面地址：http://hd.master:4040

### 本地模式提交应用

在spark目录下执行

```shell
bin/spark-submit --class org.apache.spark.examples.SparkPi --master local[4] ./examples/jars/spark-examples_2.12-3.5.4.jar 10
```

> 命令参数解释：
>
> –class表示要执行程序的主类，此处可以更换为咱们自己写的应用程序
> –master local[2] 部署模式，默认为本地模式，数字表示分配的虚拟CPU核数量
> spark-examples_2.12-3.5.4.jar 运行的应用类所在的jar包，实际使用时，可以设定为咱们自己打的jar包
> 数字10表示程序的入口参数，用于设定当前应用的任务数量

执行完成后输出如下：

```
24/12/27 11:04:12 INFO SparkContext: Running Spark version 3.5.4
24/12/27 11:04:12 INFO SparkContext: OS info Linux, 3.10.0-1160.el7.x86_64, amd64
24/12/27 11:04:12 INFO SparkContext: Java version 1.8.0_211
24/12/27 11:04:12 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
24/12/27 11:04:12 INFO ResourceUtils: ==============================================================
24/12/27 11:04:12 INFO ResourceUtils: No custom resources configured for spark.driver.
24/12/27 11:04:12 INFO ResourceUtils: ==============================================================
24/12/27 11:04:12 INFO SparkContext: Submitted application: Spark Pi
24/12/27 11:04:12 INFO ResourceProfile: Default ResourceProfile created, executor resources: Map(cores -> name: cores, amount: 1, script: , vendor: , memory -> name: memory, amount: 1024, script: , vendor: , offHeap -> name: offHeap, amount: 0, script: , vendor: ), task resources: Map(cpus -> name: cpus, amount: 1.0)
24/12/27 11:04:12 INFO ResourceProfile: Limiting resource is cpu
24/12/27 11:04:12 INFO ResourceProfileManager: Added ResourceProfile id: 0
24/12/27 11:04:12 INFO SecurityManager: Changing view acls to: root
24/12/27 11:04:12 INFO SecurityManager: Changing modify acls to: root
24/12/27 11:04:12 INFO SecurityManager: Changing view acls groups to:
24/12/27 11:04:12 INFO SecurityManager: Changing modify acls groups to:
24/12/27 11:04:12 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users with view permissions: root; groups with view permissions: EMPTY; users with modify permissions: root; groups with modify permissions: EMPTY
24/12/27 11:04:12 INFO Utils: Successfully started service 'sparkDriver' on port 45122.
24/12/27 11:04:12 INFO SparkEnv: Registering MapOutputTracker
24/12/27 11:04:12 INFO SparkEnv: Registering BlockManagerMaster
24/12/27 11:04:12 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
24/12/27 11:04:12 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up
24/12/27 11:04:12 INFO SparkEnv: Registering BlockManagerMasterHeartbeat
24/12/27 11:04:12 INFO DiskBlockManager: Created local directory at /tmp/blockmgr-27ac4579-84f9-49d7-b1ef-b5e16c14898f
24/12/27 11:04:12 INFO MemoryStore: MemoryStore started with capacity 366.3 MiB
24/12/27 11:04:12 INFO SparkEnv: Registering OutputCommitCoordinator
24/12/27 11:04:13 INFO JettyUtils: Start Jetty 0.0.0.0:4040 for SparkUI
24/12/27 11:04:13 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.
24/12/27 11:04:13 INFO Utils: Successfully started service 'SparkUI' on port 4041.
24/12/27 11:04:13 INFO SparkContext: Added JAR file:/usr/local/spark-3.5.4-bin-hadoop3/examples/jars/spark-examples_2.12-3.5.4.jar at spark://hd.master:45122/jars/spark-examples_2.12-3.5.4.jar with timestamp 1735268652233
24/12/27 11:04:13 INFO Executor: Starting executor ID driver on host hd.master
24/12/27 11:04:13 INFO Executor: OS info Linux, 3.10.0-1160.el7.x86_64, amd64
24/12/27 11:04:13 INFO Executor: Java version 1.8.0_211
24/12/27 11:04:13 INFO Executor: Starting executor with user classpath (userClassPathFirst = false): ''
24/12/27 11:04:13 INFO Executor: Created or updated repl class loader org.apache.spark.util.MutableURLClassLoader@76c52298 for default.
24/12/27 11:04:13 INFO Executor: Fetching spark://hd.master:45122/jars/spark-examples_2.12-3.5.4.jar with timestamp 1735268652233
24/12/27 11:04:13 INFO TransportClientFactory: Successfully created connection to hd.master/10.8.1.189:45122 after 32 ms (0 ms spent in bootstraps)
24/12/27 11:04:13 INFO Utils: Fetching spark://hd.master:45122/jars/spark-examples_2.12-3.5.4.jar to /tmp/spark-6c026f70-ea97-466c-ac64-91063aed010f/userFiles-9ca80b06-2691-4dd5-a8db-4480a48835f7/fetchFileTemp8540032884399255584.tmp
24/12/27 11:04:13 INFO Executor: Adding file:/tmp/spark-6c026f70-ea97-466c-ac64-91063aed010f/userFiles-9ca80b06-2691-4dd5-a8db-4480a48835f7/spark-examples_2.12-3.5.4.jar to class loader default
24/12/27 11:04:13 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 43158.
24/12/27 11:04:13 INFO NettyBlockTransferService: Server created on hd.master:43158
24/12/27 11:04:13 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
24/12/27 11:04:13 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, hd.master, 43158, None)
24/12/27 11:04:13 INFO BlockManagerMasterEndpoint: Registering block manager hd.master:43158 with 366.3 MiB RAM, BlockManagerId(driver, hd.master, 43158, None)
24/12/27 11:04:13 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, hd.master, 43158, None)
24/12/27 11:04:13 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, hd.master, 43158, None)
24/12/27 11:04:14 INFO SparkContext: Starting job: reduce at SparkPi.scala:38
24/12/27 11:04:14 INFO DAGScheduler: Got job 0 (reduce at SparkPi.scala:38) with 10 output partitions
24/12/27 11:04:14 INFO DAGScheduler: Final stage: ResultStage 0 (reduce at SparkPi.scala:38)
24/12/27 11:04:14 INFO DAGScheduler: Parents of final stage: List()
24/12/27 11:04:14 INFO DAGScheduler: Missing parents: List()
24/12/27 11:04:14 INFO DAGScheduler: Submitting ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34), which has no missing parents
24/12/27 11:04:14 INFO MemoryStore: Block broadcast_0 stored as values in memory (estimated size 4.0 KiB, free 366.3 MiB)
24/12/27 11:04:14 INFO MemoryStore: Block broadcast_0_piece0 stored as bytes in memory (estimated size 2.3 KiB, free 366.3 MiB)
24/12/27 11:04:14 INFO BlockManagerInfo: Added broadcast_0_piece0 in memory on hd.master:43158 (size: 2.3 KiB, free: 366.3 MiB)
24/12/27 11:04:14 INFO SparkContext: Created broadcast 0 from broadcast at DAGScheduler.scala:1585
24/12/27 11:04:14 INFO DAGScheduler: Submitting 10 missing tasks from ResultStage 0 (MapPartitionsRDD[1] at map at SparkPi.scala:34) (first 15 tasks are for partitions Vector(0, 1, 2, 3, 4, 5, 6, 7, 8, 9))
24/12/27 11:04:14 INFO TaskSchedulerImpl: Adding task set 0.0 with 10 tasks resource profile 0
24/12/27 11:04:14 INFO TaskSetManager: Starting task 0.0 in stage 0.0 (TID 0) (hd.master, executor driver, partition 0, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:14 INFO TaskSetManager: Starting task 1.0 in stage 0.0 (TID 1) (hd.master, executor driver, partition 1, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:14 INFO TaskSetManager: Starting task 2.0 in stage 0.0 (TID 2) (hd.master, executor driver, partition 2, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:14 INFO TaskSetManager: Starting task 3.0 in stage 0.0 (TID 3) (hd.master, executor driver, partition 3, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:14 INFO Executor: Running task 0.0 in stage 0.0 (TID 0)
24/12/27 11:04:14 INFO Executor: Running task 3.0 in stage 0.0 (TID 3)
24/12/27 11:04:14 INFO Executor: Running task 1.0 in stage 0.0 (TID 1)
24/12/27 11:04:14 INFO Executor: Running task 2.0 in stage 0.0 (TID 2)
24/12/27 11:04:15 INFO Executor: Finished task 3.0 in stage 0.0 (TID 3). 1055 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Starting task 4.0 in stage 0.0 (TID 4) (hd.master, executor driver, partition 4, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO Executor: Running task 4.0 in stage 0.0 (TID 4)
24/12/27 11:04:15 INFO Executor: Finished task 2.0 in stage 0.0 (TID 2). 1012 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Starting task 5.0 in stage 0.0 (TID 5) (hd.master, executor driver, partition 5, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO Executor: Running task 5.0 in stage 0.0 (TID 5)
24/12/27 11:04:15 INFO Executor: Finished task 0.0 in stage 0.0 (TID 0). 1012 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Finished task 2.0 in stage 0.0 (TID 2) in 877 ms on hd.master (executor driver) (1/10)
24/12/27 11:04:15 INFO TaskSetManager: Finished task 3.0 in stage 0.0 (TID 3) in 889 ms on hd.master (executor driver) (2/10)
24/12/27 11:04:15 INFO TaskSetManager: Starting task 6.0 in stage 0.0 (TID 6) (hd.master, executor driver, partition 6, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO Executor: Running task 6.0 in stage 0.0 (TID 6)
24/12/27 11:04:15 INFO Executor: Finished task 1.0 in stage 0.0 (TID 1). 1012 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Starting task 7.0 in stage 0.0 (TID 7) (hd.master, executor driver, partition 7, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO TaskSetManager: Finished task 0.0 in stage 0.0 (TID 0) in 969 ms on hd.master (executor driver) (3/10)
24/12/27 11:04:15 INFO Executor: Running task 7.0 in stage 0.0 (TID 7)
24/12/27 11:04:15 INFO TaskSetManager: Finished task 1.0 in stage 0.0 (TID 1) in 942 ms on hd.master (executor driver) (4/10)
24/12/27 11:04:15 INFO Executor: Finished task 5.0 in stage 0.0 (TID 5). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Starting task 8.0 in stage 0.0 (TID 8) (hd.master, executor driver, partition 8, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO Executor: Finished task 4.0 in stage 0.0 (TID 4). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Finished task 5.0 in stage 0.0 (TID 5) in 143 ms on hd.master (executor driver) (5/10)
24/12/27 11:04:15 INFO Executor: Running task 8.0 in stage 0.0 (TID 8)
24/12/27 11:04:15 INFO Executor: Finished task 6.0 in stage 0.0 (TID 6). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Starting task 9.0 in stage 0.0 (TID 9) (hd.master, executor driver, partition 9, PROCESS_LOCAL, 9309 bytes)
24/12/27 11:04:15 INFO TaskSetManager: Finished task 4.0 in stage 0.0 (TID 4) in 177 ms on hd.master (executor driver) (6/10)
24/12/27 11:04:15 INFO TaskSetManager: Finished task 6.0 in stage 0.0 (TID 6) in 116 ms on hd.master (executor driver) (7/10)
24/12/27 11:04:15 INFO Executor: Running task 9.0 in stage 0.0 (TID 9)
24/12/27 11:04:15 INFO Executor: Finished task 8.0 in stage 0.0 (TID 8). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Finished task 8.0 in stage 0.0 (TID 8) in 73 ms on hd.master (executor driver) (8/10)
24/12/27 11:04:15 INFO Executor: Finished task 7.0 in stage 0.0 (TID 7). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Finished task 7.0 in stage 0.0 (TID 7) in 170 ms on hd.master (executor driver) (9/10)
24/12/27 11:04:15 INFO Executor: Finished task 9.0 in stage 0.0 (TID 9). 969 bytes result sent to driver
24/12/27 11:04:15 INFO TaskSetManager: Finished task 9.0 in stage 0.0 (TID 9) in 87 ms on hd.master (executor driver) (10/10)
24/12/27 11:04:15 INFO TaskSchedulerImpl: Removed TaskSet 0.0, whose tasks have all completed, from pool
24/12/27 11:04:15 INFO DAGScheduler: ResultStage 0 (reduce at SparkPi.scala:38) finished in 1.335 s
24/12/27 11:04:15 INFO DAGScheduler: Job 0 is finished. Cancelling potential speculative or zombie tasks for this job
24/12/27 11:04:15 INFO TaskSchedulerImpl: Killing all running tasks in stage 0: Stage finished
24/12/27 11:04:15 INFO DAGScheduler: Job 0 finished: reduce at SparkPi.scala:38, took 1.392080 s
Pi is roughly 3.142871142871143
24/12/27 11:04:15 INFO SparkContext: SparkContext is stopping with exitCode 0.
24/12/27 11:04:15 INFO SparkUI: Stopped Spark web UI at http://hd.master:4041
24/12/27 11:04:15 INFO MapOutputTrackerMasterEndpoint: MapOutputTrackerMasterEndpoint stopped!
24/12/27 11:04:15 INFO MemoryStore: MemoryStore cleared
24/12/27 11:04:15 INFO BlockManager: BlockManager stopped
24/12/27 11:04:15 INFO BlockManagerMaster: BlockManagerMaster stopped
24/12/27 11:04:15 INFO OutputCommitCoordinator$OutputCommitCoordinatorEndpoint: OutputCommitCoordinator stopped!
24/12/27 11:04:15 INFO SparkContext: Successfully stopped SparkContext
24/12/27 11:04:15 INFO ShutdownHookManager: Shutdown hook called
24/12/27 11:04:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-6c026f70-ea97-466c-ac64-91063aed010f
24/12/27 11:04:15 INFO ShutdownHookManager: Deleting directory /tmp/spark-30e9a44e-0e19-4f56-b357-da96fb9ba2ac
```

可以看到正确输出了圆周率

### 退出

```shell
:qiut
```

 ## Standalone模式

### 编写配置文件

#### 配置spark-env.sh

```shell
#拷贝模版文件
cp spark-env.sh.template spark-env.sh

#编辑文件
vi spark-env.sh

#添加以下内容，替换成自己的jdk、hadoop路径
export JAVA_HOME=/usr/local/jdk1.8.0_211
export HADOOP_HOME=/opt/hadoop/hadoop-3.4.0
export HADOOP_CONF_DIR=/opt/hadoop/hadoop-3.4.0/etc/hadoop
export JAVA_LIBRAY_PATH=/opt/hadoop/hadoop-3.4.0/lib/native
export SPARK_DIST_CLASSPATH=$(/opt/hadoop/hadoop-3.4.0/bin/hadoop classpath)

export SPARK_MASTER_HOST=hd.master
export SPARK_MASTER_PORT=7077

export SPARK_WORKER_MEMORY=4g
export SPARK_WORKER_CORES=4
export SPARK_MASTER_WEBUI_PORT=6633

export SPARK_HISTORY_OPTS="
-Dspark.history.ui.port=18080 
-Dspark.history.retainedApplications=30 
-Dspark.history.fs.logDirectory=hdfs://hd.master/spark-log"

```

#### 配置workers

```shell
#拷贝模版文件
cp workers.template workers

#编辑文件
vim workers

#添加以下内容
hd.master
hd.slave1
hd.slave2
```

#### 配置历史日志

```shell
#拷贝模版文件
cp spark-defaults.conf.template spark-defaults.conf

#编辑文件
vim spark-defaults.conf

#添加以下内容
spark.eventLog.enabled           true
spark.eventLog.dir               hdfs://hd.master:9000/spark-log

# hdfs中创建日志文件夹
hdfs dfs -mkdir /spark-log

#编辑spark环境变量文件
vim spark-env.sh

#增加以下配置
export SPARK_HISTORY_OPTS="
-Dspark.history.ui.port=18080 
-Dspark.history.retainedApplications=30 
-Dspark.history.fs.logDirectory=hdfs://hd.master:9000/spark-log"

```

> 上边的hdfs配置的端口可以查看hadoop中的core-site.xml中配置的hdfs的nameNode的地址，配置项如下：
>
> <property>
> 	<name>fs.defaultFS</name>
> 	<value>hdfs://hd.master:9000</value>
>   </property>

#### 修改spark启动脚本名称

修改名称的目的是由于hadoop中有同名的启动脚本，避免混淆

```shell
mv start-all.sh start-spark.sh
mv stop-all.sh stop-spark.sh
```

### 将spark文件夹拷贝到其他节点

```shell
 #拷贝到从节点1
 scp -r spark-3.5.4-bin-hadoop3 root@hd.slave1:/usr/local
 
 #拷贝到从节点2
 scp -r spark-3.5.4-bin-hadoop3 root@hd.slave2:/usr/local
```

### 启动

```shell
start-spark.sh
start-history-server.sh
```

### webUI

http://hd.master:6633

### 提交作业到集群

```shell
spark-submit \
--class org.apache.spark.examples.SparkPi \
--master spark://hd.master:7077 \
./examples/jars/spark-examples_2.12-3.5.4.jar \
10
```

> 成功后可以看到输出和上报Local模式一样的日志内容

#### 遇到的问题

提交作业的时候提示一下错误：

```
org.apache.hadoop.ipc.RpcException: RPC response exceeds maximum data length
```

解决方案如下：

```xml
vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml
   
'''在文件最后中添加片段 '''
<property>
     <name>ipc.maximum.data.length</name>
     <value>134217728</value>
</property>
```

### 提交作业到yarn

```shell
spark-submit \
--master yarn \
--class  org.apache.spark.examples.SparkPi \
./examples/jars/spark-examples_2.12-3.5.4.jar \
10

```

## HA模式

待完善。。。
